{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d37d6de-cbd0-4fe4-98f1-a8c41113bb84",
   "metadata": {},
   "source": [
    "## Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab2397-2025-4376-a796-4b440449ea05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "778c6546-54dd-41b5-b4aa-a530e41f4c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests>=2.20 in ./env/lib/python3.11/site-packages (from openai) (2.31.0)\n",
      "Collecting tqdm (from openai)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in ./env/lib/python3.11/site-packages (from openai) (3.8.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.11/site-packages (from requests>=2.20->openai) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.11/site-packages (from requests>=2.20->openai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./env/lib/python3.11/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./env/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./env/lib/python3.11/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./env/lib/python3.11/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./env/lib/python3.11/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./env/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, openai\n",
      "Successfully installed openai-0.28.1 tqdm-4.66.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "896cab48-886e-4724-864d-6600e5d99cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf2b3b60-95f4-48b9-af73-6b60f0b0e5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91098cf3-ed6c-4ab0-8e69-e7e300622c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.3,\n",
    "                 openai_api_key=OPENAI_API_KEY,\n",
    "                 model_name='gpt-3.5-turbo-0613',\n",
    "                 # model_name='gpt-4',\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0011dbdb-1c38-4416-bec8-f57a5e017e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(llm, quant_topic, quant_title):\n",
    "    # It would be nice to bring in information about the links, pictures, etc.\n",
    "    system_template = \"\"\"\n",
    "        You are an incredibly wise and smart quantitative analyst that lives and breathes the world of quantitative finance.\n",
    "        Your goal is to writing short-form content for twitter given a `topic` in the area of quantitative finance and a `title` from the user.\n",
    "        \n",
    "        % RESPONSE TONE:\n",
    "\n",
    "        - Your response should be given in an active voice and be opinionated\n",
    "        - Your tone should be serious w/ a hint of wit and sarcasm\n",
    "        \n",
    "        % RESPONSE FORMAT:\n",
    "        \n",
    "        - Be extremely clear and concise\n",
    "        - Respond in short phrases\n",
    "        - No longer than 40 words total\n",
    "        - Total of 280 characters (counting spaces and other characters)\n",
    "        - Do not respond with emojis\n",
    "        \n",
    "        % RESPONSE CONTENT:\n",
    "\n",
    "        - Include specific examples of where this is used in the quantitative finance space\n",
    "        - If you don't have an answer, say, \"Sorry, I'll have to ask the Quant Finance Gods!\"    \n",
    "\n",
    "        % RESPONSE TEMPLATE:\n",
    "\n",
    "        - Here’s a condensed structure tailored for Twitter's 280-character limit: \n",
    "            Hook: Captivate with a one-liner.\n",
    "            Intro: Briefly introduce the topic.\n",
    "            Explanation: Simplify the core idea.\n",
    "            Application: Note real-world relevance.\n",
    "            Closing: Reflective one-liner.\n",
    "            Action: Short engagement call.\n",
    "            Engagement: Quick question.\n",
    "    \n",
    "    \"\"\"\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "    human_template=\"topic to write about is {topic}, and the title will be {title}. Keep the total response under 200 characters total! respond in short phrases, only one sentence maximium per line no more than 6 words\"\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template, \n",
    "                                                                    input_variables=[\"topic\", \"title\"])\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, \n",
    "                                                    human_message_prompt])\n",
    "\n",
    "    # get a chat completion from the formatted messages\n",
    "    final_prompt = chat_prompt.format_prompt(topic=quant_topic, \n",
    "                                             title=quant_title).to_messages()\n",
    "    first_response = llm(final_prompt).content\n",
    "\n",
    "    ai_message_prompt = AIMessagePromptTemplate.from_template(first_response)\n",
    "\n",
    "    # reminder of length\n",
    "    reminder_template=\"This was good, but way too long, please make your response much more concise and much shorter! Please maintain the existing template.\"\n",
    "    reminder_prompt = HumanMessagePromptTemplate.from_template(reminder_template)\n",
    "\n",
    "    chat_prompt2 = ChatPromptTemplate.from_messages([system_message_prompt, \n",
    "                                                     human_template, \n",
    "                                                     ai_message_prompt, \n",
    "                                                     reminder_prompt])\n",
    "\n",
    "    # get a chat completion from the formatted messages\n",
    "    final_prompt = chat_prompt2.format_prompt(topic=quant_topic, \n",
    "                                              title=quant_title).to_messages()\n",
    "    short_response = llm(final_prompt).content\n",
    "\n",
    "    return first_response, short_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "db0bbe9b-2446-48ab-a0f6-b5a3f7632886",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_response, short_response = generate_response(llm, quant_topic='Time Value of Money', quant_title='Unveiling the Magic of Compounding: Time Value of Money')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "29cc4abd-8773-4ab9-8dee-7829c936ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_length = lambda d: sum(len(d[val]) for val in d)\n",
    "def extract_tweet(openai_tweet):\n",
    "    \"\"\"Return\n",
    "    \"\"\"\n",
    "    key_list=[\"Hook\", \"Intro\", \"Explanation\", \"Application\", \"Closing\", \"Action\", \"Engagement\"]\n",
    "    for i, key in enumerate(key_list):\n",
    "        start = openai_tweet.find(key_list[i])+len(key_list[i])+2\n",
    "        if i != len(key_list) - 1:\n",
    "            end = openai_tweet.find(key_list[i+1])\n",
    "            line = openai_tweet[start:end]\n",
    "            template[key_list[i]] = line\n",
    "        else:\n",
    "            template[key_list[i]] = openai_tweet[start:]\n",
    "    return template, count_length(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "aea93379-daaf-4da4-9a58-d34b6fbcdd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Hook': 'Discover the enchantment of compounding!\\n',\n",
       "  'Intro': 'Unveiling the Time Value of Money.\\n',\n",
       "  'Explanation': 'Money grows exponentially over time.\\n',\n",
       "  'Application': 'Investing, loans, retirement planning, and more.\\n',\n",
       "  'Closing': 'Embrace the power of compounding!\\n',\n",
       "  'Action': 'Start investing today!\\n',\n",
       "  'Engagement': 'How has compounding changed your financial outlook?'},\n",
       " 270)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_tweet(first_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "2bc4f946-ed5d-4ff0-bc71-0e7693af4aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Hook': 'Unveiling the magic of compounding!\\n',\n",
       "  'Intro': 'Time Value of Money explained.\\n',\n",
       "  'Explanation': 'Money grows exponentially over time.\\n',\n",
       "  'Application': 'Investing, loans, retirement planning, and more.\\n',\n",
       "  'Closing': 'Embrace the power of compounding!\\n',\n",
       "  'Action': 'Start investing today!\\n',\n",
       "  'Engagement': 'How has compounding changed your finances?'},\n",
       " 252)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_tweet(short_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa0e02-9408-48b2-8900-3742efa28b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
